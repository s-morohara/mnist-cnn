{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "import keras.layers as layers\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTデータを読込む\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train[:, :, :, np.newaxis]\n",
    "x_test = x_test[:, :, :, np.newaxis]\n",
    "# one-hot化\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 入力層\n",
    "img_input = layers.Input(shape=x_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第１層\n",
    "block1_channel = 8\n",
    "x = layers.Conv2D(block1_channel, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(block1_channel, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第2層\n",
    "block2_channel = block1_channel  * 2\n",
    "x = layers.Conv2D(block2_channel, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(block2_channel, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Conv2D(block2_channel, (3, 3), activation='relu', padding='same', name='block2_conv3')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全結合相\n",
    "conv_denses = 256\n",
    "x = layers.Flatten(name='flatten')(x)\n",
    "x = layers.Dense(conv_denses , activation='relu', name='fc1')(x)\n",
    "x = layers.Dropout(0.5, name='dropout1')(x)\n",
    "x = layers.Dense(conv_denses , activation='relu', name='fc2')(x)\n",
    "x = layers.Dropout(0.5, name='dropout2')(x)\n",
    "x = layers.Dense(10, activation='softmax', name='predictions')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル構築\n",
    "model = Model(img_input, x, name='vgg16')\n",
    "adam = Adam()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.3999 - acc: 0.8767 - val_loss: 0.0656 - val_acc: 0.9786\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.1072 - acc: 0.9697 - val_loss: 0.0429 - val_acc: 0.9862\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0780 - acc: 0.9785 - val_loss: 0.0368 - val_acc: 0.9875\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.0648 - acc: 0.9817 - val_loss: 0.0418 - val_acc: 0.9872\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.0553 - acc: 0.9840 - val_loss: 0.0315 - val_acc: 0.9905\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.0491 - acc: 0.9863 - val_loss: 0.0347 - val_acc: 0.9899\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0433 - acc: 0.9877 - val_loss: 0.0322 - val_acc: 0.9898\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.0401 - acc: 0.9884 - val_loss: 0.0363 - val_acc: 0.9890\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 96s 2ms/step - loss: 0.0372 - acc: 0.9894 - val_loss: 0.0367 - val_acc: 0.9883\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.0335 - acc: 0.9906 - val_loss: 0.0323 - val_acc: 0.9906\n"
     ]
    }
   ],
   "source": [
    "# 学習\n",
    "BATCH_SIZE = 128\n",
    "EPOCH = 10\n",
    "history = model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCH,  verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルと重みの保存\n",
    "json_string = model.to_json()\n",
    "open(\"my_model.json\", 'w').write(json_string)\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 345us/step\n",
      "\n",
      "Test loss: 11.46660728149414\n",
      "Test accuracy: 0.0977\n"
     ]
    }
   ],
   "source": [
    "# 検証\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print()\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 間違い見つける\n",
    "predicts = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.5959816e-08 1.2570596e-12 2.9274310e-09 1.0498509e-01 2.4628214e-04\n",
      " 6.2673655e-12 1.5349119e-08 8.3537827e-10 8.9476866e-01 1.8763105e-08]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "number=1\n",
    "print(predicts[number,:])\n",
    "print(y_test[number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
